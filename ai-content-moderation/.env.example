# =============================================================================
# AI CONTENT MODERATION SERVICE - EXAMPLE ENVIRONMENT VARIABLES
# =============================================================================
# 
# This file contains example values for all environment variables used by the
# AI Content Moderation service. Copy this file to .env and update with your
# actual values.
#
# IMPORTANT: Never commit actual secrets to version control!
# =============================================================================

# =============================================================================
# REQUIRED ENVIRONMENT VARIABLES
# =============================================================================
# These variables are mandatory - the application will not start without them

# -----------------------------------------------------------------------------
# Security Configuration
# -----------------------------------------------------------------------------
SECRET_KEY=your-super-secret-flask-key-at-least-32-chars-long-cryptographically-strong

# Application Environment
FLASK_ENV=development

# =============================================================================
# OPTIONAL ENVIRONMENT VARIABLES
# =============================================================================
# These variables enhance functionality but are not required for basic operation

# -----------------------------------------------------------------------------
# Server Configuration
# -----------------------------------------------------------------------------
PORT=5001
FLASK_DEBUG=1

# -----------------------------------------------------------------------------
# Ollama Configuration
# -----------------------------------------------------------------------------
OLLAMA_HOST=http://localhost:11434
OLLAMA_PORT=11434
EMBEDDING_MODEL=mxbai-embed-large

# -----------------------------------------------------------------------------
# Content Moderation Thresholds
# -----------------------------------------------------------------------------
TOXICITY_THRESHOLD=0.7
CONFIDENCE_THRESHOLD=0.8
MENTAL_HEALTH_THRESHOLD=0.6

# -----------------------------------------------------------------------------
# Performance & Scaling
# -----------------------------------------------------------------------------
MAX_CONTENT_LENGTH=10000
BATCH_SIZE_LIMIT=100
CACHE_TTL=604800

# -----------------------------------------------------------------------------
# Rate Limiting
# -----------------------------------------------------------------------------
RATE_LIMIT_PER_MINUTE=30
RATE_LIMIT_PER_HOUR=1000

# -----------------------------------------------------------------------------
# Authentication
# -----------------------------------------------------------------------------
API_KEY_REQUIRED=false
API_KEY=your_api_key_here

# -----------------------------------------------------------------------------
# Backend Integration
# -----------------------------------------------------------------------------
BACKEND_API_URL=http://localhost:3001
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# -----------------------------------------------------------------------------
# Redis Configuration (Optional)
# -----------------------------------------------------------------------------
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=defaultpassword

# -----------------------------------------------------------------------------
# Monitoring & Logging
# -----------------------------------------------------------------------------
LOG_LEVEL=DEBUG
ENABLE_METRICS=true
ENABLE_LOGGING=true

# =============================================================================
# PRODUCTION ENVIRONMENT EXAMPLE
# =============================================================================
# For production deployment, use values similar to these:
#
# FLASK_ENV=production
# FLASK_DEBUG=0
# PORT=80
# SECRET_KEY=cryptographically-strong-random-secret-32-plus-characters
# OLLAMA_HOST=http://ollama:11434
# EMBEDDING_MODEL=mxbai-embed-large
# TOXICITY_THRESHOLD=0.8
# CONFIDENCE_THRESHOLD=0.9
# MENTAL_HEALTH_THRESHOLD=0.7
# MAX_CONTENT_LENGTH=20000
# BATCH_SIZE_LIMIT=200
# CACHE_TTL=86400
# RATE_LIMIT_PER_MINUTE=100
# RATE_LIMIT_PER_HOUR=5000
# API_KEY_REQUIRED=true
# API_KEY=production-api-key-here
# BACKEND_API_URL=https://api.mentara.app
# CORS_ORIGINS=https://mentara.app,https://api.mentara.app
# REDIS_HOST=redis-cluster
# REDIS_PORT=6379
# REDIS_DB=0
# REDIS_PASSWORD=strong-redis-password
# LOG_LEVEL=WARNING
# ENABLE_METRICS=true
# ENABLE_LOGGING=true

# =============================================================================
# GETTING STARTED
# =============================================================================
# 
# 1. Copy this file to .env in the same directory:
#    cp .env.example .env
#
# 2. Update the values with your actual configuration:
#    - Generate a strong SECRET_KEY (32+ characters)
#    - Configure Ollama host if not using Docker Compose
#    - Set appropriate thresholds for your use case
#    - Configure Redis if using caching
#
# 3. Ensure Ollama is set up:
#    - Install Ollama: https://ollama.ai/
#    - Start Ollama service: ollama serve
#    - Pull embedding model: ollama pull mxbai-embed-large
#
# 4. Start the development server:
#    python api.py
#    # or with Make: make dev
#
# =============================================================================
# OLLAMA REQUIREMENTS
# =============================================================================
#
# Ollama Installation:
# - Download from: https://ollama.ai/
# - Start service: ollama serve
# - Default host: http://localhost:11434
#
# Required Models:
# - mxbai-embed-large: Primary embedding model (~2GB)
#   Download: ollama pull mxbai-embed-large
#
# Model Performance:
# - Embedding generation: ~100ms per request
# - Memory usage: 2-4GB depending on model
# - GPU acceleration: Supported with CUDA/Metal
#
# Alternative Models:
# - all-minilm: Smaller, faster model (~25MB)
# - nomic-embed-text: Alternative embedding model (~140MB)
# - sentence-transformers: Various options available
#
# =============================================================================
# CONTENT MODERATION CONFIGURATION
# =============================================================================
#
# Threshold Guidelines:
# - TOXICITY_THRESHOLD (0.0-1.0):
#   * 0.5: Very sensitive, catches mild negativity
#   * 0.7: Balanced, catches clearly toxic content
#   * 0.9: Very permissive, only extreme toxicity
#
# - CONFIDENCE_THRESHOLD (0.0-1.0):
#   * 0.7: Lower confidence, more false positives
#   * 0.8: Balanced confidence level
#   * 0.9: High confidence, fewer false positives
#
# - MENTAL_HEALTH_THRESHOLD (0.0-1.0):
#   * 0.5: Sensitive to mental health discussions
#   * 0.6: Balanced mental health detection
#   * 0.8: Only clear mental health content
#
# Rate Limiting:
# - Development: 30/minute, 1000/hour
# - Production: 100/minute, 5000/hour
# - Crisis detection: Unlimited (bypasses rate limits)
#
# =============================================================================
# MENTAL HEALTH FEATURES
# =============================================================================
#
# Crisis Detection Categories:
# - Suicide ideation and self-harm
# - Severe depression and hopelessness
# - Psychotic episodes and reality distortion
# - Immediate danger statements
# - Crisis keywords and phrases
#
# Mental Health Context Detection:
# - Depression and mood disorders
# - Anxiety and stress-related content
# - Trauma and PTSD discussions
# - Eating disorders and body image
# - Substance abuse and recovery
# - Bipolar and mood cycling
# - OCD and compulsive behaviors
# - ADHD and attention issues
# - Personality disorders
#
# Therapeutic Context Awareness:
# - Therapy session discussions
# - Treatment progress sharing
# - Recovery narratives and success stories
# - Support group conversations
# - Professional therapeutic language
#
# =============================================================================
# PERFORMANCE TUNING
# =============================================================================
#
# Development Environment:
# - CACHE_TTL=300 (5 minutes) for testing
# - BATCH_SIZE_LIMIT=50 for lower resource usage
# - LOG_LEVEL=DEBUG for verbose output
# - Single worker process
#
# Staging Environment:
# - CACHE_TTL=3600 (1 hour) for realistic testing
# - BATCH_SIZE_LIMIT=100 for balanced performance
# - LOG_LEVEL=INFO for important events
# - Multiple worker processes
#
# Production Environment:
# - CACHE_TTL=86400 (24 hours) for performance
# - BATCH_SIZE_LIMIT=200 for high throughput
# - LOG_LEVEL=WARNING for essential logs only
# - Optimized worker processes and scaling
#
# Memory Optimization:
# - Use Redis for caching to reduce memory usage
# - Configure Ollama model unloading for low usage
# - Monitor memory usage with multiple models
#
# =============================================================================
# INTEGRATION NOTES
# =============================================================================
#
# Backend API Integration:
# - Service receives moderation requests from NestJS backend
# - Backend handles user authentication and request validation
# - AI service focuses on content analysis and moderation
# - Results include action recommendations and reasoning
#
# Expected Performance:
# - Single request: ~200ms average response time
# - Batch processing: ~50ms per item in batch
# - Throughput: 300+ requests/minute (single instance)
# - Memory usage: ~4GB with embeddings and caching
#
# Error Handling:
# - 503 errors when Ollama is unavailable
# - 400 errors for invalid input format
# - 429 errors when rate limit exceeded
# - 422 errors for content that's too long
# - Detailed error messages in development mode
#
# Crisis Response:
# - Immediate flagging of crisis content
# - Bypass rate limits for emergency situations
# - Integration with crisis intervention systems
# - Audit logging for all crisis detections
#
# =============================================================================
# SECURITY REMINDERS
# =============================================================================
# 
# ✅ DO:
# - Use strong, unique SECRET_KEY for each environment
# - Enable API key authentication in production
# - Use secure Redis passwords
# - Enable HTTPS for all external communications
# - Monitor rate limiting logs for abuse patterns
# - Regularly update dependencies and models
# - Implement proper audit logging for compliance
# - Use encrypted Redis connections in production
#
# ❌ DON'T:
# - Commit secrets to version control
# - Use development settings in production
# - Store sensitive content permanently
# - Expose internal error details to clients
# - Use weak or default passwords
# - Deploy without proper input validation
# - Log sensitive user content
# - Share API keys across environments
#
# =============================================================================
# COMPLIANCE CONSIDERATIONS
# =============================================================================
#
# HIPAA Compliance:
# - Audit logging enabled for all moderation decisions
# - Content not stored permanently (configurable)
# - Access controls via API key authentication
# - Encryption in transit for all communications
# - Configurable data retention policies
#
# Privacy Protection:
# - Minimal data collection and processing
# - Optional content anonymization
# - Secure caching with encryption support
# - User consent and transparency features
# - Data deletion and right to be forgotten
#
# =============================================================================