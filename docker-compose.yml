# Mentara Production-Ready Docker Compose
# AI/DevOps Agent Implementation
# HIPAA-Compliant Microservices Architecture

version: '3.8'

services:
  # PostgreSQL Database with Security Hardening
  postgres:
    image: postgres:15-alpine
    container_name: mentara-postgres
    environment:
      POSTGRES_DB: mentara_db
      POSTGRES_USER: mentara_admin
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_INITDB_ARGS: "--data-checksums"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./security-hardening/configs/postgresql.conf.security:/etc/postgresql/postgresql.conf
      - ./security-hardening/configs/pg_hba.conf.security:/etc/postgresql/pg_hba.conf
    ports:
      - "5432:5432"
    networks:
      - mentara-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U mentara_admin -d mentara_db"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis for Session Management and Caching
  redis:
    image: redis:7-alpine
    container_name: mentara-redis
    command: redis-server --requirepass ${REDIS_PASSWORD} --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - mentara-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Backend API Service
  api:
    build:
      context: ./mentara-api
      dockerfile: Dockerfile
    container_name: mentara-api
    environment:
      NODE_ENV: production
      DATABASE_URL: postgresql://mentara_admin:${DB_PASSWORD}@postgres:5432/mentara_db?sslmode=require
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      JWT_SECRET: ${JWT_SECRET}
      ENCRYPTION_KEY: ${ENCRYPTION_KEY}
    ports:
      - "3001:3001"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - mentara-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Ollama Service for AI Content Moderation
  ollama:
    image: ollama/ollama:latest
    container_name: mentara-ollama
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    networks:
      - mentara-network
    restart: unless-stopped
    environment:
      - OLLAMA_ORIGINS=*
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # AI Patient Evaluation Service
  ai-service:
    build:
      context: ./ai-patient-evaluation
      dockerfile: Dockerfile
    container_name: mentara-ai
    environment:
      FLASK_ENV: production
      MENTARA_AI_API_KEY: ${AI_API_KEY}
    ports:
      - "5000:5000"
    networks:
      - mentara-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # AI Content Moderation Service
  ai-content-moderation:
    build:
      context: ./ai-content-moderation
      dockerfile: Dockerfile
    container_name: mentara-ai-content-mod
    environment:
      FLASK_ENV: production
      OLLAMA_HOST: http://ollama:11434
      EMBEDDING_MODEL: mxbai-embed-large
      REDIS_HOST: redis
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      TOXICITY_THRESHOLD: 0.7
      CONFIDENCE_THRESHOLD: 0.8
      MENTAL_HEALTH_THRESHOLD: 0.6
      LOG_LEVEL: INFO
    ports:
      - "5001:5001"
    depends_on:
      ollama:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - moderation_models:/app/models
      - moderation_logs:/app/logs
    networks:
      - mentara-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Frontend Service
  frontend:
    build:
      context: ./mentara-client
      dockerfile: Dockerfile
    container_name: mentara-frontend
    environment:
      NODE_ENV: production
      NEXT_PUBLIC_API_URL: http://api:3001
      NEXT_PUBLIC_AI_SERVICE_URL: http://ai-service:5000
    ports:
      - "3000:3000"
    depends_on:
      - api
      - ai-service
    networks:
      - mentara-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Nginx Reverse Proxy with SSL
  nginx:
    image: nginx:alpine
    container_name: mentara-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./security-hardening/configs/nginx.conf:/etc/nginx/conf.d/default.conf
      - ./security-hardening/certs:/etc/ssl/certs
      - ./security-hardening/logs:/var/log/nginx
    depends_on:
      - frontend
      - api
      - ai-service
    networks:
      - mentara-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Monitoring and Logging
  prometheus:
    image: prom/prometheus:latest
    container_name: mentara-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - mentara-network
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: mentara-grafana
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - mentara-network
    restart: unless-stopped

  # Log Aggregation
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: mentara-elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - mentara-network

  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    container_name: mentara-logstash
    volumes:
      - ./monitoring/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    depends_on:
      - elasticsearch
    networks:
      - mentara-network

  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    container_name: mentara-kibana
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - mentara-network

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ollama_data:
    driver: local
  moderation_models:
    driver: local
  moderation_logs:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  elasticsearch_data:
    driver: local

networks:
  mentara-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16